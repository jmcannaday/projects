{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f029619",
   "metadata": {},
   "source": [
    "<br>\n",
    "<center>\n",
    "\n",
    "# Assignments for Week 3\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edacd0d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right; width: 15%; margin-left: auto;\">\n",
    "    \n",
    "Jon Cannaday <br>\n",
    "DSC 550 <br>\n",
    "3/28/2024  \n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecbcf7c",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33e2b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948b8e4b",
   "metadata": {},
   "source": [
    "## Part 1: Using the TextBlob Sentiment Analyzer\n",
    "<br>\n",
    "<div style=\"width: 100%; border-bottom: 1px solid black;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952cb7af",
   "metadata": {},
   "source": [
    "   - ### Import the movie review data as a data frame and ensure that the data is loaded properly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d194929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "       id  sentiment                                             review\n",
      "0  5814_8          1  With all this stuff going down at the moment w...\n",
      "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
      "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
      "3  3630_4          0  It must be assumed that those who praised this...\n",
      "4  9495_8          1  Superbly trashy and wondrously unpretentious 8...\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\Users\\Owner\\OneDrive\\Desktop\\DataScience\\2024_Spring_DataMining\\labeledTrainData.tsv'\n",
    "data = pd.read_csv(path, sep='\\t')\n",
    "\n",
    "\n",
    "print(type(data)) # Data type\n",
    "print()\n",
    "print(data.head()) # Data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd514faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id  sentiment                                             review\n",
      "0       5814_8          1  With all this stuff going down at the moment w...\n",
      "1       2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
      "2       7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
      "3       3630_4          0  It must be assumed that those who praised this...\n",
      "4       9495_8          1  Superbly trashy and wondrously unpretentious 8...\n",
      "...        ...        ...                                                ...\n",
      "24995   3453_3          0  It seems like more consideration has gone into...\n",
      "24996   5064_1          0  I don't believe they made this film. Completel...\n",
      "24997  10905_3          0  Guy is a loser. Can't get girls, needs to buil...\n",
      "24998  10194_3          0  This 30 minute documentary BuÃ±uel made in the ...\n",
      "24999   8478_8          1  I saw this movie as a child and it broke my he...\n",
      "\n",
      "[25000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148ad2ab",
   "metadata": {},
   "source": [
    "   - ### How many of each positive and negative reviews are there?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0aece52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive reviews:  12500\n",
      "Negative reviews:  12500\n"
     ]
    }
   ],
   "source": [
    "positive = data[data['sentiment'] == 1] # Boolean filter where condition it true\n",
    "negative = data[data['sentiment'] == 0]\n",
    "\n",
    "print(\"Positive reviews: \", len(positive)) # Number of elements\n",
    "print(\"Negative reviews: \", len(negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82eb4be",
   "metadata": {},
   "source": [
    "   - ### Use TextBlob to classify each movie review as positive or negative. Assume that a polarity score greater than or equal to zero is a positive sentiment and less than 0 is a negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c221e331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0        1\n",
      "1        1\n",
      "2        0\n",
      "3        1\n",
      "4        0\n",
      "        ..\n",
      "24995    1\n",
      "24996    1\n",
      "24997    1\n",
      "24998    1\n",
      "24999    1\n",
      "Name: predicted_sentiment, Length: 25000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create prediction column using Polarity which quantifies the sentiment returns binary \n",
    "data['predicted_sentiment'] = data['review'].apply(lambda text: 1 if TextBlob(text).sentiment.polarity >= 0 else 0)\n",
    "\n",
    "print()\n",
    "print(data['predicted_sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429ea04b",
   "metadata": {},
   "source": [
    "   - ### Check the accuracy of this model. Is this model better than random guessing?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "50cb738b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model accuracy :  0.68524\n",
      "\n",
      "Which would be better than guessing, we have a 50/50 shot at guessing correctly.\n"
     ]
    }
   ],
   "source": [
    "accuracy_textblob = accuracy_score(data['sentiment'], data['predicted_sentiment']) # Accuracy statment\n",
    "print()\n",
    "print(\"Model accuracy : \", accuracy_textblob) # Results\n",
    "print()\n",
    "print(\"Which would be better than guessing, we have a 50/50 shot at guessing correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6effe6a",
   "metadata": {},
   "source": [
    "   - ### For up to five points extra credit, use another prebuilt text sentiment analyzer, e.g., VADER, and repeat steps (3) and (4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "85ae86ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VADER model accuracy :  0.69356\n"
     ]
    }
   ],
   "source": [
    "vader_analyzer = SentimentIntensityAnalyzer() # Initiate \n",
    "\n",
    "# Create a prediction Column using the polarity scores\n",
    "data['predicted_sentiment_vader'] = data['review'].apply(lambda text: 1 if vader_analyzer.polarity_scores(text)['compound'] >= 0 else 0)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_vader = accuracy_score(data['sentiment'], data['predicted_sentiment_vader'])\n",
    "print()\n",
    "print(\"VADER model accuracy : \", accuracy_vader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b076fd",
   "metadata": {},
   "source": [
    "## Part 2: Prepping Text for a Custom Model\n",
    "<br>\n",
    "<div style=\"width: 100%; border-bottom: 1px solid black;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472de2ea",
   "metadata": {},
   "source": [
    "   - ### Convert all text to lowercase letters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e0456eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0    with all this stuff going down at the moment w...\n",
      "1    \\the classic war of the worlds\\\" by timothy hi...\n",
      "2    the film starts with a manager (nicholas bell)...\n",
      "3    it must be assumed that those who praised this...\n",
      "4    superbly trashy and wondrously unpretentious 8...\n",
      "Name: review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data['review'] = data['review'].str.lower() # Lower case\n",
    "print()\n",
    "print(data['review'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8632ab",
   "metadata": {},
   "source": [
    "   - ### Remove punctuation and special characters from the text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d5fe1da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0    with all this stuff going down at the moment w...\n",
      "1    the classic war of the worlds by timothy hines...\n",
      "2    the film starts with a manager nicholas bell g...\n",
      "3    it must be assumed that those who praised this...\n",
      "4    superbly trashy and wondrously unpretentious 8...\n",
      "Name: review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# not in logic to remove the punctuation\n",
    "data['review'] = data['review'].apply(lambda text: ''.join(char for char in text if char not in string.punctuation))\n",
    "print()\n",
    "print(data['review'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a902d0",
   "metadata": {},
   "source": [
    "   - ### Remove stop words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "13e90df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0    stuff going moment mj ive started listening mu...\n",
      "1    classic war worlds timothy hines entertaining ...\n",
      "2    film starts manager nicholas bell giving welco...\n",
      "3    must assumed praised film greatest filmed oper...\n",
      "4    superbly trashy wondrously unpretentious 80s e...\n",
      "Name: review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# not in logic to remove the stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "data['review'] = data['review'].apply(lambda text: ' '.join(word for word in text.split() if word not in stop_words))\n",
    "\n",
    "print()\n",
    "print(data['review'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a005699",
   "metadata": {},
   "source": [
    "   - ### Apply NLTKâs PorterStemmer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4d770938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0    stuff go moment mj ive start listen music watc...\n",
      "1    classic war world timothi hine entertain film ...\n",
      "2    film start manag nichola bell give welcom inve...\n",
      "3    must assum prais film greatest film opera ever...\n",
      "4    superbl trashi wondrous unpretenti 80 exploit ...\n",
      "Name: review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Initiates PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# create a review column and split \n",
    "data['review'] = data['review'].apply(lambda text: ' '.join(stemmer.stem(word) for word in text.split()))\n",
    "\n",
    "print()\n",
    "print(data['review'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cef0e6d",
   "metadata": {},
   "source": [
    "   - ### Create a bag-of-words matrix from your stemmed text (output from (4)), where each row is a word-count vector for a single movie review (see sections 5.3 & 6.8 in the Machine Learning with Python Cookbook). Display the dimensions of your bag-of-words matrix. The number of rows in this matrix should be the same as the number of rows in your original data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eeab0fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the bag-of-words matrix: (25000, 91587)\n"
     ]
    }
   ],
   "source": [
    "# initiates port stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Custom column \n",
    "data['review'] = data['review'].apply(lambda text: ' '.join(stemmer.stem(word) for word in text.split()))\n",
    "\n",
    "# Matrix\n",
    "vectorizer = CountVectorizer()\n",
    "bag_of_words_matrix = vectorizer.fit_transform(data['review'])\n",
    "\n",
    "# Matrix dimensions\n",
    "print(\"Dimensions of the bag-of-words matrix:\", bag_of_words_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f231a2f3",
   "metadata": {},
   "source": [
    "   - ### Create a term frequency-inverse document frequency (tf-idf) matrix from your stemmed text, for your movie reviews (see section 6.9 in the Machine Learning with Python Cookbook). Display the dimensions of your tf-idf matrix. These dimensions should be the same as your bag-of-words matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b01e26c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the tf-idf matrix: (25000, 91473)\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Custom colum that passes each split work idto the stemmer\n",
    "data['review'] = data['review'].apply(lambda text: ' '.join(stemmer.stem(word) for word in text.split()))\n",
    "\n",
    "# tf-idf matrix\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data['review'])\n",
    "\n",
    "# tf-idf Matrix dimensions\n",
    "print(\"Dimensions of the tf-idf matrix:\", tfidf_matrix.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
